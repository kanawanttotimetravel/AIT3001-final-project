{"cells":[{"cell_type":"markdown","metadata":{"id":"t0wDNXGtID2B"},"source":["# Install and setup"]},{"cell_type":"markdown","metadata":{},"source":["The first block have to be executed twice to fully install the neccessary modules"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-12-13T16:15:05.950412Z","iopub.status.busy":"2024-12-13T16:15:05.949514Z","iopub.status.idle":"2024-12-13T16:16:19.645704Z","shell.execute_reply":"2024-12-13T16:16:19.644617Z","shell.execute_reply.started":"2024-12-13T16:15:05.950375Z"},"id":"s_vNEvTpIF9C","outputId":"0d022bac-9a1e-4886-b71a-688b3c7453ca","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n","Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\n","Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.26.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n","\u001b[0mCollecting en-core-web-sm==3.0.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.0.0) (3.0.9)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.12)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.10)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.9)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.17)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.11)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.10)\n","Collecting typer<0.4.0,>=0.3.0 (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0)\n","  Using cached typer-0.3.2-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.11.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.66.4)\n","Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.8.2)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.1.4)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (70.0.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.1.2)\n","Requirement already satisfied: pathlib-abc==0.1.1 in /opt/conda/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2024.6.2)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.1.5)\n","Using cached typer-0.3.2-py3-none-any.whl (21 kB)\n","Installing collected packages: typer, en-core-web-sm\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.13.1\n","    Uninstalling typer-0.13.1:\n","      Successfully uninstalled typer-0.13.1\n","  Attempting uninstall: en-core-web-sm\n","    Found existing installation: en_core_web_sm 3.8.0\n","    Uninstalling en_core_web_sm-3.8.0:\n","      Successfully uninstalled en_core_web_sm-3.8.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastapi-cli 0.0.4 requires typer>=0.12.3, but you have typer 0.3.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed en-core-web-sm-3.0.0 typer-0.3.2\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","Requirement already satisfied: torchtext==0.6.0 in /opt/conda/lib/python3.10/site-packages (0.6.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (4.66.4)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (2.32.3)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (2.4.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (1.26.4)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (1.16.0)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (0.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.6.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.6.0) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.6.0) (2024.6.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (2024.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n","Requirement already satisfied: pyvi in /opt/conda/lib/python3.10/site-packages (0.1.1)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\n","Requirement already satisfied: sklearn-crfsuite in /opt/conda/lib/python3.10/site-packages (from pyvi) (0.5.0)\n","Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.26.4)\n","Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.14.1)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.5.0)\n","Requirement already satisfied: python-crfsuite>=0.9.7 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.11)\n","Requirement already satisfied: tabulate>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.66.4)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (0.3.8)\n","Collecting https://gitlab.com/trungtv/vi_spacy/-/raw/master/vi_core_news_lg/dist/vi_core_news_lg-0.0.1.tar.gz\n","  Using cached https://gitlab.com/trungtv/vi_spacy/-/raw/master/vi_core_news_lg/dist/vi_core_news_lg-0.0.1.tar.gz (254.5 MB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.5 in /opt/conda/lib/python3.10/site-packages (from vi_core_news_lg==0.0.1) (3.0.9)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (3.0.12)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (2.0.10)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (3.0.9)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (8.0.17)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (0.7.11)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (2.0.10)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (0.3.2)\n","Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (0.11.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (4.66.4)\n","Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (1.26.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (1.8.2)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (3.1.4)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (70.0.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (3.1.2)\n","Requirement already satisfied: pathlib-abc==0.1.1 in /opt/conda/lib/python3.10/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (0.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (2024.6.2)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.1.0,>=3.0.5->vi_core_news_lg==0.0.1) (2.1.5)\n"]}],"source":["!pip install datasets transformers evaluate\n","!python -m spacy download en_core_web_sm\n","!pip install torchtext==0.6.0\n","!pip install pyvi\n","!pip install dill\n","!pip install https://gitlab.com/trungtv/vi_spacy/-/raw/master/vi_core_news_lg/dist/vi_core_news_lg-0.0.1.tar.gz"]},{"cell_type":"markdown","metadata":{"id":"Tf20NNW_H_Gh"},"source":["# Import\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-12-13T16:16:19.648521Z","iopub.status.busy":"2024-12-13T16:16:19.648031Z","iopub.status.idle":"2024-12-13T16:16:21.208578Z","shell.execute_reply":"2024-12-13T16:16:21.207341Z","shell.execute_reply.started":"2024-12-13T16:16:19.648474Z"},"id":"-x1tyLdee520","outputId":"3eeda668-5ac0-4aa2-8cfa-71c977e73660","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6.0\n"]}],"source":["import torchtext\n","print(torchtext.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:21.210341Z","iopub.status.busy":"2024-12-13T16:16:21.209840Z","iopub.status.idle":"2024-12-13T16:16:26.318614Z","shell.execute_reply":"2024-12-13T16:16:26.317627Z","shell.execute_reply.started":"2024-12-13T16:16:21.210299Z"},"id":"TMQSWkgTlHFe","trusted":true},"outputs":[],"source":["import torch\n","from torch import nn, optim\n","from torch.optim import Adam\n","import torch.utils.data as data\n","import math\n","from collections import Counter\n","import numpy as np\n","import copy\n","import time\n","import spacy\n","import re\n","from torchtext import data\n","import pandas as pd\n","from torch.autograd import Variable\n","import dill as pickle\n","import spacy\n","import torch.nn.functional as F\n","from torchtext.data.metrics import bleu_score\n","import os\n","import nltk\n","from tqdm import tqdm_notebook as tqdm"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-12-13T16:16:26.320934Z","iopub.status.busy":"2024-12-13T16:16:26.320416Z","iopub.status.idle":"2024-12-13T16:16:26.435647Z","shell.execute_reply":"2024-12-13T16:16:26.434733Z","shell.execute_reply.started":"2024-12-13T16:16:26.320904Z"},"id":"AogMFQ7yfGVL","outputId":"a80f85d6-354c-4e84-a9e0-4f199f392117","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('wordnet')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:26.436993Z","iopub.status.busy":"2024-12-13T16:16:26.436722Z","iopub.status.idle":"2024-12-13T16:16:27.791494Z","shell.execute_reply":"2024-12-13T16:16:27.790339Z","shell.execute_reply.started":"2024-12-13T16:16:26.436967Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]},{"name":"stdout","output_type":"stream","text":["Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n","   creating: /usr/share/nltk_data/corpora/wordnet/\n","  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n","  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n"]}],"source":["!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:27.793535Z","iopub.status.busy":"2024-12-13T16:16:27.793120Z","iopub.status.idle":"2024-12-13T16:16:27.798791Z","shell.execute_reply":"2024-12-13T16:16:27.797909Z","shell.execute_reply.started":"2024-12-13T16:16:27.793494Z"},"trusted":true},"outputs":[],"source":["from nltk.corpus import wordnet"]},{"cell_type":"markdown","metadata":{},"source":["# Download dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:27.800148Z","iopub.status.busy":"2024-12-13T16:16:27.799876Z","iopub.status.idle":"2024-12-13T16:16:31.733148Z","shell.execute_reply":"2024-12-13T16:16:31.732309Z","shell.execute_reply.started":"2024-12-13T16:16:27.800122Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"27259ffcf8604f3bb4474ecdb3b265e2","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66e608cb6c4049a78b8028f29d6a0e99","version_major":2,"version_minor":0},"text/plain":["(…)-00000-of-00001-8fc21cb8e80d3a2d.parquet:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"151acb58a7a5422d974169ac3b6e4b53","version_major":2,"version_minor":0},"text/plain":["(…)-00000-of-00001-858c0e989d9c5637.parquet:   0%|          | 0.00/1.42M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44dcfb9e9a424382a72f149dbff1df64","version_major":2,"version_minor":0},"text/plain":["(…)-00000-of-00001-99e7e50144d1c164.parquet:   0%|          | 0.00/1.42M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28beef063c4242df80093411524cd7db","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/203272 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ca1d60005334eea95f98f3882eb285a","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/25409 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3efe1be5e9654f438668acbf60b89661","version_major":2,"version_minor":0},"text/plain":["Generating valid split:   0%|          | 0/25409 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import datasets\n","\n","dataset = datasets.load_dataset(\"harouzie/vi_en-translation\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:31.734959Z","iopub.status.busy":"2024-12-13T16:16:31.734475Z","iopub.status.idle":"2024-12-13T16:16:31.738978Z","shell.execute_reply":"2024-12-13T16:16:31.738237Z","shell.execute_reply.started":"2024-12-13T16:16:31.734930Z"},"id":"4dEsAegsIaBd","trusted":true},"outputs":[],"source":["train_data, test_data, valid_data = (dataset['train'], dataset['test'], dataset['valid'])"]},{"cell_type":"markdown","metadata":{"id":"L0wR78rDIboz"},"source":["# The model"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-12-13T16:16:31.740244Z","iopub.status.busy":"2024-12-13T16:16:31.739996Z","iopub.status.idle":"2024-12-13T16:16:31.799138Z","shell.execute_reply":"2024-12-13T16:16:31.798319Z","shell.execute_reply.started":"2024-12-13T16:16:31.740218Z"},"id":"fcYXFtHJIdNm","outputId":"cb212a75-a2d0-488e-ddc0-aecca608b2b8","trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([4, 512])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["class Embedder(nn.Module):\n","  def __init__(self, vocab_size, model_dim):\n","    super(Embedder, self).__init__()\n","    self.vocab_size = vocab_size\n","    self.model = model_dim\n","\n","    self.embed = nn.Embedding(vocab_size, model_dim)\n","\n","  def forward(self, x):\n","    return self.embed(x)\n","\n","Embedder(100, 512)(torch.LongTensor([1,2,3,4])).shape\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-12-13T16:16:31.802247Z","iopub.status.busy":"2024-12-13T16:16:31.801967Z","iopub.status.idle":"2024-12-13T16:16:32.506704Z","shell.execute_reply":"2024-12-13T16:16:32.505488Z","shell.execute_reply.started":"2024-12-13T16:16:31.802219Z"},"id":"g1A9-DjttjaR","outputId":"bc8b6f5d-cb53-45b9-ddfa-4b5834013f60","trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([5, 30, 512])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["class PositionalEncoder(nn.Module):\n","    def __init__(self, d_model, max_seq_length=200, dropout=0.1):\n","        super().__init__()\n","\n","        self.d_model = d_model\n","        self.dropout = nn.Dropout(dropout)\n","\n","        pe = torch.zeros(max_seq_length, d_model)\n","\n","        for pos in range(max_seq_length):\n","            for i in range(0, d_model, 2):\n","                pe[pos, i] = math.sin(pos/(10000**(2*i/d_model)))\n","                pe[pos, i+1] = math.cos(pos/(10000**((2*i+1)/d_model)))\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","\n","      x = x*math.sqrt(self.d_model)\n","      seq_length = x.size(1)\n","\n","      pe = Variable(self.pe[:, :seq_length], requires_grad=False)\n","\n","      if x.is_cuda:\n","          pe.cuda()\n","      x = x + pe\n","      x = self.dropout(x)\n","\n","      return x\n","\n","PositionalEncoder(512)(torch.rand(5, 30, 512)).shape"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:32.508226Z","iopub.status.busy":"2024-12-13T16:16:32.507840Z","iopub.status.idle":"2024-12-13T16:16:32.514096Z","shell.execute_reply":"2024-12-13T16:16:32.513243Z","shell.execute_reply.started":"2024-12-13T16:16:32.508171Z"},"id":"ua5qHFGsicBg","trusted":true},"outputs":[],"source":["def attention(q, k, v, mask=None, dropout=None):\n","    \"\"\"Compute the attention scores and output.\n","\n","    Args:\n","        q (torch.Tensor): Query tensor of shape (batch_size, num_heads, seq_length, d_k).\n","        k (torch.Tensor): Key tensor of shape (batch_size, num_heads, seq_length, d_k).\n","        v (torch.Tensor): Value tensor of shape (batch_size, num_heads, seq_length, d_v).\n","        mask (torch.Tensor, optional): Mask tensor to prevent attention to certain positions. \n","                                       Shape should be (batch_size, 1, seq_length) or \n","                                       (batch_size, num_heads, seq_length). Defaults to None.\n","        dropout (torch.nn.Module, optional): Dropout layer to apply to the attention scores. \n","                                              Defaults to None.\n","\n","    Returns:\n","        torch.Tensor: The output tensor after applying attention, shape (batch_size, num_heads, seq_length, d_v).\n","        torch.Tensor: The attention scores, shape (batch_size, num_heads, seq_length, seq_length).\n","    \"\"\"\n","    d_k = q.size(-1)\n","    scores = torch.matmul(q, k.transpose(-2, -1))/math.sqrt(d_k)\n","\n","    if mask is not None:\n","        mask = mask.unsqueeze(1)\n","        scores = scores.masked_fill(mask==0, -1e9)\n","    scores = F.softmax(scores, dim=-1)\n","\n","    if dropout is not None:\n","        scores = dropout(scores)\n","\n","    output = torch.matmul(scores, v)\n","    return output, scores"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:32.515580Z","iopub.status.busy":"2024-12-13T16:16:32.515292Z","iopub.status.idle":"2024-12-13T16:16:32.524291Z","shell.execute_reply":"2024-12-13T16:16:32.523436Z","shell.execute_reply.started":"2024-12-13T16:16:32.515554Z"},"id":"Bv6OHNWaxq6v","trusted":true},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    \"\"\"\n","    Multi-Head Attention mechanism as described in the \"Attention is All You Need\" paper.\n","\n","    This class implements the multi-head attention mechanism, which allows the model to jointly \n","    attend to information from different representation subspaces at different positions. \n","    It consists of multiple attention heads that compute attention scores and outputs in parallel.\n","\n","    Attributes:\n","        d_model (int): The dimensionality of the input and output embeddings.\n","        d_k (int): The dimensionality of the key vectors (d_model / heads).\n","        h (int): The number of attention heads.\n","        attn (torch.Tensor): The attention scores from the last forward pass.\n","        q_linear (nn.Linear): Linear transformation for the query vectors.\n","        k_linear (nn.Linear): Linear transformation for the key vectors.\n","        v_linear (nn.Linear): Linear transformation for the value vectors.\n","        dropout (nn.Dropout): Dropout layer applied to the attention scores.\n","        out (nn.Linear): Linear transformation applied to the concatenated output of all heads.\n","\n","    Methods:\n","        forward(q, k, v, mask=None):\n","            Computes the multi-head attention output and attention scores.\n","\n","    Args:\n","        heads (int): The number of attention heads.\n","        d_model (int): The dimensionality of the input and output embeddings.\n","        dropout (float, optional): The dropout rate for the attention scores. Default is 0.1.\n","    \"\"\"\n","    def __init__(self, heads, d_model, dropout=0.1):\n","        super().__init__()\n","        assert d_model % heads == 0\n","\n","        self.d_model = d_model\n","        self.d_k = d_model//heads\n","        self.h = heads\n","        self.attn = None\n","\n","        # tạo ra 3 ma trận trọng số là q_linear, k_linear, v_linear\n","        self.q_linear = nn.Linear(d_model, d_model)\n","        self.k_linear = nn.Linear(d_model, d_model)\n","        self.v_linear = nn.Linear(d_model, d_model)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.out = nn.Linear(d_model, d_model)\n","\n","    def forward(self, q, k, v, mask=None):\n","        \"\"\"\n","        q: [batch_size, seq_length, d_model]\n","        k: [batch_size, seq_length, d_model]\n","        v: [batch_size, seq_length, d_model]\n","        mask: [batch_size, 1, seq_length]\n","        output: [batch_size, seq_length, d_model]\n","        \"\"\"\n","        bs = q.size(0)\n","\n","        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n","        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n","        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n","\n","        q = q.transpose(1, 2)\n","        k = k.transpose(1, 2)\n","        v = v.transpose(1, 2)\n","        scores, self.attn = attention(q, k, v, mask, self.dropout)\n","\n","        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n","\n","        output = self.out(concat)\n","        return output\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:32.525664Z","iopub.status.busy":"2024-12-13T16:16:32.525383Z","iopub.status.idle":"2024-12-13T16:16:32.536522Z","shell.execute_reply":"2024-12-13T16:16:32.535752Z","shell.execute_reply.started":"2024-12-13T16:16:32.525626Z"},"id":"nOMjdxhe2AYw","trusted":true},"outputs":[],"source":["class Norm(nn.Module):\n","    \"\"\"\n","    Layer normalization class.\n","\n","    This class implements layer normalization, which normalizes the input across the features dimension.\n","    \n","    Attributes:\n","        size (int): The dimensionality of the input.\n","        alpha (nn.Parameter): Learnable scale parameter.\n","        bias (nn.Parameter): Learnable bias parameter.\n","        eps (float): A small value to avoid division by zero during normalization.\n","\n","    Args:\n","        d_model (int): The dimensionality of the input.\n","        eps (float, optional): A small value to avoid division by zero. Default is 1e-6.\n","    \"\"\"\n","    def __init__(self, d_model, eps = 1e-6):\n","        super().__init__()\n","\n","        self.size = d_model\n","\n","        self.alpha = nn.Parameter(torch.ones(self.size))\n","        self.bias = nn.Parameter(torch.zeros(self.size))\n","\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass for layer normalization.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor of shape (batch_size, ..., d_model).\n","\n","        Returns:\n","            torch.Tensor: Normalized output tensor.\n","        \"\"\"\n","        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n","        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n","        return norm\n","\n","class FeedForward(nn.Module):\n","    \"\"\"\n","    Feedforward neural network class.\n","\n","    This class implements a feedforward neural network with two linear transformations and a ReLU activation function.\n","    \n","    Attributes:\n","        linear_1 (nn.Linear): First linear transformation.\n","        dropout (nn.Dropout): Dropout layer applied after the first linear transformation.\n","        linear_2 (nn.Linear): Second linear transformation.\n","\n","    Args:\n","        d_model (int): The dimensionality of the input.\n","        d_ff (int, optional): The dimensionality of the hidden layer. Default is 2048.\n","        dropout (float, optional): Dropout rate. Default is 0.1.\n","    \"\"\"\n","    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n","        super().__init__()\n","\n","        # set d_ff as a default to 2048\n","        self.linear_1 = nn.Linear(d_model, d_ff)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear_2 = nn.Linear(d_ff, d_model)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass for the feedforward network.\n","\n","        Args:\n","            x (torch.Tensor): Input tensor of shape (batch_size, seq_length, d_model).\n","\n","        Returns:\n","            torch.Tensor: Output tensor of shape (batch_size, seq_length, d_model).\n","        \"\"\"\n","        x = self.dropout(F.relu(self.linear_1(x)))\n","        x = self.linear_2(x)\n","        return x"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:32.537837Z","iopub.status.busy":"2024-12-13T16:16:32.537589Z","iopub.status.idle":"2024-12-13T16:16:32.550296Z","shell.execute_reply":"2024-12-13T16:16:32.549615Z","shell.execute_reply.started":"2024-12-13T16:16:32.537814Z"},"id":"is50y_Ho2CRA","trusted":true},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout=0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)\n","        self.ff = FeedForward(d_model, dropout=dropout)\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","\n","        x2 = self.norm_1(x)\n","        # calculate attention value\n","        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n","        x2 = self.norm_2(x)\n","        x = x + self.dropout_2(self.ff(x2))\n","        return x"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:32.551582Z","iopub.status.busy":"2024-12-13T16:16:32.551232Z","iopub.status.idle":"2024-12-13T16:16:32.562402Z","shell.execute_reply":"2024-12-13T16:16:32.561647Z","shell.execute_reply.started":"2024-12-13T16:16:32.551547Z"},"id":"gEMUS7rq2EFo","trusted":true},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout=0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.norm_3 = Norm(d_model)\n","\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","        self.dropout_3 = nn.Dropout(dropout)\n","\n","        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)\n","        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)\n","        self.ff = FeedForward(d_model, dropout=dropout)\n","\n","    def forward(self, x, e_outputs, src_mask, trg_mask):\n","        \"\"\"\n","        x: [batch_siz, seq_length, d_model]\n","        e_outputs: [batch_siz, seq_length, d_model]\n","        src_mask: [batch_size, 1, seq_length]\n","        trg_mask: [batch_size, 1, seq_length]\n","        \"\"\"\n","        x2 = self.norm_1(x)\n","        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n","        x2 = self.norm_2(x)\n","\n","        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n","        x2 = self.norm_3(x)\n","        x = x + self.dropout_3(self.ff(x2))\n","        return x"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:32.563816Z","iopub.status.busy":"2024-12-13T16:16:32.563487Z","iopub.status.idle":"2024-12-13T16:16:32.576408Z","shell.execute_reply":"2024-12-13T16:16:32.575542Z","shell.execute_reply.started":"2024-12-13T16:16:32.563786Z"},"id":"Kbq-O_JB2FLr","trusted":true},"outputs":[],"source":["import copy\n","\n","def get_clones(module, N):\n","    \"\"\"\n","    Create N identical clones of a given module.\n","\n","    Args:\n","        module (nn.Module): The module to clone.\n","        N (int): The number of clones to create.\n","\n","    Returns:\n","        nn.ModuleList: A list containing N deep copies of the input module.\n","    \"\"\"\n","    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n","\n","class Encoder(nn.Module):\n","    \"\"\"\n","    Encoder class for the Transformer model.\n","\n","    This class implements the encoder part of the Transformer architecture, which processes the input sequence\n","    and generates a sequence of continuous representations.\n","\n","    Attributes:\n","        N (int): The number of encoder layers.\n","        embed (Embedder): The embedding layer for input tokens.\n","        pe (PositionalEncoder): The positional encoding layer to add positional information to the embeddings.\n","        layers (nn.ModuleList): A list of encoder layers.\n","        norm (Norm): Layer normalization applied to the output of the encoder.\n","\n","    Args:\n","        vocab_size (int): The size of the vocabulary.\n","        d_model (int): The dimensionality of the model (embedding size).\n","        N (int): The number of encoder layers.\n","        heads (int): The number of attention heads.\n","        dropout (float): The dropout rate for regularization.\n","\n","    Methods:\n","        forward(src, mask):\n","            Processes the input sequence and returns the encoded representations.\n","\n","    Args:\n","        src (torch.Tensor): Input tensor of shape (batch_size, seq_length).\n","        mask (torch.Tensor): Mask tensor of shape (batch_size, 1, seq_length) to prevent attention to certain positions.\n","\n","    Returns:\n","        torch.Tensor: The output tensor of shape (batch_size, seq_length, d_model) after processing through the encoder.\n","    \"\"\"\n","    def __init__(self, vocab_size, d_model, N, heads, dropout):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model, dropout=dropout)\n","        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n","        self.norm = Norm(d_model)\n","\n","    def forward(self, src, mask):\n","        \"\"\"\n","        Forward pass for the encoder.\n","\n","        Args:\n","            src (torch.Tensor): Input tensor of shape (batch_size, seq_length).\n","            mask (torch.Tensor): Mask tensor of shape (batch_size, 1, seq_length).\n","\n","        Returns:\n","            torch.Tensor: The output tensor of shape (batch_size, seq_length, d_model).\n","        \"\"\"\n","        x = self.embed(src)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x, mask)\n","        return self.norm(x)\n","\n","class Decoder(nn.Module):\n","    \"\"\"\n","    Decoder class for the Transformer model.\n","\n","    This class implements the decoder part of the Transformer architecture, which generates the output sequence\n","    based on the encoded representations and the previous output tokens.\n","\n","    Attributes:\n","        N (int): The number of decoder layers.\n","        embed (Embedder): The embedding layer for target tokens.\n","        pe (PositionalEncoder): The positional encoding layer to add positional information to the embeddings.\n","        layers (nn.ModuleList): A list of decoder layers.\n","        norm (Norm): Layer normalization applied to the output of the decoder.\n","\n","    Args:\n","        vocab_size (int): The size of the vocabulary.\n","        d_model (int): The dimensionality of the model (embedding size).\n","        N (int): The number of decoder layers.\n","        heads (int): The number of attention heads.\n","        dropout (float): The dropout rate for regularization.\n","\n","    Methods:\n","        forward(trg, e_outputs, src_mask, trg_mask):\n","            Processes the target sequence and returns the decoded output.\n","\n","    Args:\n","        trg (torch.Tensor): Target tensor of shape (batch_size, seq_length).\n","        e_outputs (torch.Tensor): Encoded outputs from the encoder of shape (batch_size, seq_length, d_model).\n","        src_mask (torch.Tensor): Mask tensor for the source input of shape (batch_size, 1, seq_length).\n","        trg_mask (torch.Tensor): Mask tensor for the target input of shape (batch_size, 1, seq_length).\n","\n","    Returns:\n","        torch.Tensor: The output tensor of shape (batch_size, seq_length, d_model) after processing through the decoder.\n","    \"\"\"\n","    def __init__(self, vocab_size, d_model, N, heads, dropout):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model, dropout=dropout)\n","        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n","        self.norm = Norm(d_model)\n","\n","    def forward(self, trg, e_outputs, src_mask, trg_mask):\n","        \"\"\"\n","        Forward pass for the decoder.\n","\n","        Args:\n","            trg (torch.Tensor): Target tensor of shape (batch_size, seq_length).\n","            e_outputs (torch.Tensor): Encoded outputs from the encoder of shape (batch_size, seq_length, d_model).\n","            src_mask (torch.Tensor): Mask tensor for the source input of shape (batch_size, 1, seq_length).\n","            trg_mask (torch.Tensor): Mask tensor for the target input of shape (batch_size, 1, seq_length).\n","\n","        Returns:\n","            torch.Tensor: The output tensor of shape (batch_size, seq_length, d_model).\n","        \"\"\"\n","        x = self.embed(trg)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n","        return self.norm(x)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:32.578356Z","iopub.status.busy":"2024-12-13T16:16:32.577537Z","iopub.status.idle":"2024-12-13T16:16:32.593037Z","shell.execute_reply":"2024-12-13T16:16:32.592206Z","shell.execute_reply.started":"2024-12-13T16:16:32.578315Z"},"id":"29VDRNA02Oij","trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    \"\"\"\n","    Transformer model for sequence-to-sequence tasks.\n","\n","    This class implements the Transformer architecture as described in the \"Attention is All You Need\" paper.\n","    It consists of an encoder and a decoder, which are used to process input sequences and generate output sequences.\n","\n","    Attributes:\n","        encoder (Encoder): The encoder component of the Transformer, which processes the input sequence.\n","        decoder (Decoder): The decoder component of the Transformer, which generates the output sequence based on the encoded representations.\n","        out (nn.Linear): A linear layer that maps the decoder output to the target vocabulary size.\n","\n","    Args:\n","        src_vocab (int): The size of the source vocabulary.\n","        trg_vocab (int): The size of the target vocabulary.\n","        d_model (int): The dimensionality of the model (embedding size).\n","        N (int): The number of layers in both the encoder and decoder.\n","        heads (int): The number of attention heads in the multi-head attention mechanism.\n","        dropout (float): The dropout rate for regularization.\n","\n","    Methods:\n","        forward(src, trg, src_mask, trg_mask):\n","            Processes the input and target sequences through the encoder and decoder, returning the output tensor.\n","\n","    Args for forward method:\n","        src (torch.Tensor): Input tensor of shape (batch_size, seq_length) representing the source sequence.\n","        trg (torch.Tensor): Target tensor of shape (batch_size, seq_length) representing the target sequence.\n","        src_mask (torch.Tensor): Mask tensor of shape (batch_size, 1, seq_length) to prevent attention to certain positions in the source sequence.\n","        trg_mask (torch.Tensor): Mask tensor of shape (batch_size, 1, seq_length) to prevent attention to certain positions in the target sequence.\n","\n","    Returns:\n","        torch.Tensor: The output tensor of shape (batch_size, seq_length, trg_vocab) after processing through the encoder and decoder.\n","    \"\"\"\n","    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n","        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n","        self.out = nn.Linear(d_model, trg_vocab)\n","    def forward(self, src, trg, src_mask, trg_mask):\n","        \"\"\"\n","        src: [batch_size, seq_length]\n","        trg: [batch_size, seq_length]\n","        src_mask: [batch_size, 1, seq_length]\n","        trg_mask: [batch_size, 1, seq_length]\n","        output: [batch_size, seq_length, d_model]\n","        \"\"\"\n","        e_outputs = self.encoder(src, src_mask)\n","\n","        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n","        output = self.out(d_output)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"TBcwWO4CdpqT"},"source":["# Data processing and intialize data loader\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:32.594607Z","iopub.status.busy":"2024-12-13T16:16:32.594185Z","iopub.status.idle":"2024-12-13T16:16:32.621866Z","shell.execute_reply":"2024-12-13T16:16:32.620947Z","shell.execute_reply.started":"2024-12-13T16:16:32.594574Z"},"id":"r4hYEp_62W6j","trusted":true},"outputs":[],"source":["class MyIterator(data.Iterator):\n","    \"\"\"\n","    Custom iterator class for batching data in a training or evaluation loop.\n","\n","    This class extends the `data.Iterator` to create batches of data for training or evaluation.\n","    It supports shuffling and sorting of batches based on a specified key.\n","\n","    Methods:\n","        create_batches(): Creates batches of data for training or evaluation.\n","    \"\"\"\n","    def create_batches(self):\n","        if self.train:\n","            def pool(d, random_shuffler):\n","                for p in data.batch(d, self.batch_size * 100):\n","                    p_batch = data.batch(\n","                        sorted(p, key=self.sort_key),\n","                        self.batch_size, self.batch_size_fn)\n","                    for b in random_shuffler(list(p_batch)):\n","                        yield b\n","            self.batches = pool(self.data(), self.random_shuffler)\n","\n","        else:\n","            self.batches = []\n","            for b in data.batch(self.data(), self.batch_size,\n","                                          self.batch_size_fn):\n","                self.batches.append(sorted(b, key=self.sort_key))\n","\n","\n","global max_src_in_batch, max_tgt_in_batch\n","\n","def batch_size_fn(new, count, sofar):\n","    \"\"\"\n","    Function to determine the batch size based on the maximum source and target lengths.\n","\n","    Args:\n","        new: The new data instance being added to the batch.\n","        count: The current count of instances in the batch.\n","        sofar: The current size of the batch.\n","\n","    Returns:\n","        int: The size of the batch based on the maximum source and target lengths.\n","    \"\"\"\n","    global max_src_in_batch, max_tgt_in_batch\n","    if count == 1:\n","        max_src_in_batch = 0\n","        max_tgt_in_batch = 0\n","    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n","    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n","    src_elements = count * max_src_in_batch\n","    tgt_elements = count * max_tgt_in_batch\n","    return max(src_elements, tgt_elements)\n","\n","\n","def nopeak_mask(size, device):\n","    \"\"\"\n","    Creates a mask to prevent attention to future tokens in the sequence.\n","\n","    Args:\n","        size (int): The size of the sequence.\n","        device (torch.device): The device to which the mask will be moved.\n","\n","    Returns:\n","        torch.Tensor: A mask tensor of shape (1, size, size) with upper triangular values set to 0.\n","    \"\"\"\n","    np_mask = np.triu(np.ones((1, size, size)),\n","    k=1).astype('uint8')\n","    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n","    np_mask = np_mask.to(device)\n","\n","    return np_mask\n","\n","def create_masks(src, trg, src_pad, trg_pad, device):\n","    \"\"\"\n","    Creates source and target masks for the attention mechanism.\n","\n","    Args:\n","        src (torch.Tensor): The source input tensor.\n","        trg (torch.Tensor): The target input tensor.\n","        src_pad (int): The padding index for the source.\n","        trg_pad (int): The padding index for the target.\n","        device (torch.device): The device to which the masks will be moved.\n","\n","    Returns:\n","        tuple: A tuple containing the source mask and the target mask.\n","    \"\"\"\n","    src_mask = (src != src_pad).unsqueeze(-2)\n","\n","    if trg is not None:\n","        trg_mask = (trg != trg_pad).unsqueeze(-2)\n","        size = trg.size(1) # get seq_len for matrix\n","        np_mask = nopeak_mask(size, device)\n","        if trg.is_cuda:\n","            np_mask.cuda()\n","        trg_mask = trg_mask & np_mask\n","\n","    else:\n","        trg_mask = None\n","    return src_mask, trg_mask\n","\n","\n","def get_synonym(word, SRC):\n","    \"\"\"\n","    Retrieves a synonym for a given word from the WordNet corpus.\n","\n","    Args:\n","        word (str): The word for which to find a synonym.\n","        SRC: The source vocabulary object.\n","\n","    Returns:\n","        int: The index of the synonym in the vocabulary, or 0 if no synonym is found.\n","    \"\"\"\n","    syns = wordnet.synsets(word)\n","    for s in syns:\n","        for l in s.lemmas():\n","            if SRC.vocab.stoi[l.name()] != 0:\n","                return SRC.vocab.stoi[l.name()]\n","\n","    return 0\n","\n","\n","def multiple_replace(dict, text):\n","    \"\"\"\n","    Replaces multiple substrings in a given text based on a dictionary mapping.\n","\n","    Args:\n","        dict (dict): A dictionary where keys are substrings to be replaced and values are their replacements.\n","        text (str): The input text in which to perform replacements.\n","\n","    Returns:\n","        str: The modified text with replacements made.\n","    \"\"\"\n","    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n","\n","    return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)\n","\n","\n","def init_vars(src, model, SRC, TRG, device, k, max_len):\n","    \"\"\"\n","    Initializes variables for the beam search process.\n","\n","    Args:\n","        src (torch.Tensor): The source input tensor.\n","        model: The transformer model.\n","        SRC: The source vocabulary object.\n","        TRG: The target vocabulary object.\n","        device (torch.device): The device to which the tensors will be moved.\n","        k (int): The number of beams for beam search.\n","        max_len (int): The maximum length of the output sequence.\n","\n","    Returns:\n","        tuple: A tuple containing the initialized outputs, encoder outputs, and log scores.\n","    \"\"\"\n","    init_tok = TRG.vocab.stoi['<sos>']\n","    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n","\n","    e_output = model.encoder(src, src_mask)\n","\n","    outputs = torch.LongTensor([[init_tok]])\n","\n","    outputs = outputs.to(device)\n","\n","    trg_mask = nopeak_mask(1, device)\n","    out = model.out(model.decoder(outputs,\n","    e_output, src_mask, trg_mask))\n","    out = F.softmax(out, dim=-1)\n","\n","    probs, ix = out[:, -1].data.topk(k)\n","    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0)\n","\n","    outputs = torch.zeros(k, max_len).long()\n","    outputs = outputs.to(device)\n","    outputs[:, 0] = init_tok\n","    outputs[:, 1] = ix[0]\n","\n","    e_outputs = torch.zeros(k, e_output.size(-2),e_output.size(-1))\n","\n","    e_outputs = e_outputs.to(device)\n","    e_outputs[:, :] = e_output[0]\n","\n","    return outputs, e_outputs, log_scores\n","\n","def k_best_outputs(outputs, out, log_scores, i, k):\n","    \"\"\"\n","    Selects the k best outputs from the current predictions.\n","\n","    Args:\n","        outputs (torch.Tensor): The current output tensor.\n","        out (torch.Tensor): The output tensor from the model.\n","        log_scores (torch.Tensor): The log scores of the current outputs.\n","        i (int): The current index in the output sequence.\n","        k (int): The number of best outputs to select.\n","\n","    Returns:\n","        tuple: A tuple containing the updated outputs and log scores.\n","    \"\"\"\n","    probs, ix = out[:, -1].data.topk(k)\n","    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1) + log_scores.transpose(0,1)\n","    k_probs, k_ix = log_probs.view(-1).topk(k)\n","\n","    row = k_ix // k\n","    col = k_ix % k\n","\n","    outputs[:, :i] = outputs[row, :i]\n","    outputs[:, i] = ix[row, col]\n","\n","    log_scores = k_probs.unsqueeze(0)\n","\n","    return outputs, log_scores\n","\n","def beam_search(src, model, SRC, TRG, device, k, max_len):\n","    \"\"\"\n","    Performs beam search decoding for generating sequences.\n","\n","    Args:\n","        src (torch.Tensor): The source input tensor.\n","        model: The transformer model.\n","        SRC: The source vocabulary object.\n","        TRG: The target vocabulary object.\n","        device (torch.device): The device to which the tensors will be moved.\n","        k (int): The number of beams for beam search.\n","        max_len (int): The maximum length of the output sequence.\n","\n","    Returns:\n","        str: The generated output sequence as a string.\n","    \"\"\"\n","    outputs, e_outputs, log_scores = init_vars(src, model, SRC, TRG, device, k, max_len)\n","    eos_tok = TRG.vocab.stoi['<eos>']\n","    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n","    ind = None\n","    for i in range(2, max_len):\n","\n","        trg_mask = nopeak_mask(i, device)\n","\n","        out = model.out(model.decoder(outputs[:,:i],\n","        e_outputs, src_mask, trg_mask))\n","\n","        out = F.softmax(out, dim=-1)\n","\n","        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, k)\n","\n","        ones = (outputs==eos_tok).nonzero()\n","        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long).to(opt['device'])\n","        for vec in ones:\n","            i = vec[0]\n","            if sentence_lengths[i]==0:\n","                sentence_lengths[i] = vec[1]\n","\n","        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n","\n","        if num_finished_sentences == k:\n","            alpha = 0.7\n","            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n","            _, ind = torch.max(log_scores * div, 1)\n","            ind = ind.data[0]\n","            break\n","\n","    if ind is None:\n","\n","        length = (outputs[0]==eos_tok).nonzero()[0] if len((outputs[0]==eos_tok).nonzero()) > 0 else -1\n","        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[0][1:length]])\n","\n","    else:\n","        length = (outputs[ind]==eos_tok).nonzero()[0]\n","        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[ind][1:length]])\n","\n","\n","def translate_sentence(sentence, model, SRC, TRG, device, k, max_len):\n","    \"\"\"\n","    Translates a given sentence using the transformer model.\n","\n","    Args:\n","        sentence (str): The input sentence to be translated.\n","        model: The transformer model.\n","        SRC: The source vocabulary object.\n","        TRG: The target vocabulary object.\n","        device (torch.device): The device to which the tensors will be moved.\n","        k (int): The number of beams for beam search.\n","        max_len (int): The maximum length of the output sequence.\n","\n","    Returns:\n","        str: The translated sentence.\n","    \"\"\"\n","    model.eval()\n","    indexed = []\n","    sentence = SRC.preprocess(sentence)\n","\n","    for tok in sentence:\n","        if SRC.vocab.stoi[tok] != SRC.vocab.stoi['<eos>']:\n","            indexed.append(SRC.vocab.stoi[tok])\n","        else:\n","            indexed.append(get_synonym(tok, SRC))\n","\n","    sentence = Variable(torch.LongTensor([indexed]))\n","\n","    sentence = sentence.to(device)\n","\n","    sentence = beam_search(sentence, model, SRC, TRG, device, k, max_len)\n","\n","    return  multiple_replace({' ?' : '?',' !':'!',' .':'.','\\' ':'\\'',' ,':','}, sentence)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:32.623179Z","iopub.status.busy":"2024-12-13T16:16:32.622896Z","iopub.status.idle":"2024-12-13T16:16:32.639229Z","shell.execute_reply":"2024-12-13T16:16:32.638399Z","shell.execute_reply.started":"2024-12-13T16:16:32.623152Z"},"id":"OtQT_TbXdwfg","trusted":true},"outputs":[],"source":["class tokenize(object):\n","    def __init__(self, lang):\n","        self.nlp = spacy.load(lang)\n","\n","    def tokenizer(self, sentence):\n","        sentence = re.sub(\n","        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n","        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n","        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n","        sentence = re.sub(r\"\\,+\", \",\", sentence)\n","        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n","        sentence = sentence.lower()\n","        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T16:16:32.640663Z","iopub.status.busy":"2024-12-13T16:16:32.640364Z","iopub.status.idle":"2024-12-13T16:16:32.652570Z","shell.execute_reply":"2024-12-13T16:16:32.651755Z","shell.execute_reply.started":"2024-12-13T16:16:32.640636Z"},"id":"SbNqYT-xgeZb","trusted":true},"outputs":[],"source":["def create_fields(src_lang, trg_lang):\n","    \"\"\"\n","    Create source and target fields for the translation model.\n","\n","    This function initializes tokenizers for the source and target languages using spaCy,\n","    and creates data fields for processing the text data.\n","\n","    Args:\n","        src_lang (str): The language code for the source language (e.g., 'en_core_web_sm').\n","        trg_lang (str): The language code for the target language (e.g., 'vi_core_news_lg').\n","\n","    Returns:\n","        tuple: A tuple containing the source field (SRC) and target field (TRG).\n","    \"\"\"\n","    print(\"loading spacy tokenizers...\")\n","\n","    t_src = tokenize(src_lang)\n","    t_trg = tokenize(trg_lang)\n","\n","    TRG = data.Field(lower=True, tokenize=t_trg.tokenizer, init_token='<sos>', eos_token='<eos>')\n","    SRC = data.Field(lower=True, tokenize=t_src.tokenizer)\n","\n","    return SRC, TRG\n","\n","def create_dataset(src_data, trg_data, max_strlen, batchsize, device, SRC, TRG, istrain=True):\n","    \"\"\"\n","    Create a dataset and iterator for training or validation.\n","\n","    This function processes the source and target data, filters based on maximum string length,\n","    and creates a TabularDataset and a custom iterator for batching the data.\n","\n","    Args:\n","        src_data (list): A list of source sentences.\n","        trg_data (list): A list of target sentences.\n","        max_strlen (int): The maximum allowed length for source and target sentences.\n","        batchsize (int): The size of each batch for training or validation.\n","        device (torch.device): The device to which the data will be moved (CPU or GPU).\n","        SRC (data.Field): The source field for processing the source data.\n","        TRG (data.Field): The target field for processing the target data.\n","        istrain (bool): A flag indicating whether the dataset is for training (default is True).\n","\n","    Returns:\n","        MyIterator: An iterator for batching the data.\n","    \"\"\"\n","    print(\"creating dataset and iterator... \")\n","\n","    raw_data = {'src' : [line for line in src_data], 'trg': [line for line in trg_data]}\n","    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\"])\n","\n","    mask = (df['src'].str.count(' ') < max_strlen) & (df['trg'].str.count(' ') < max_strlen)\n","    df = df.loc[mask]\n","\n","    df.to_csv(\"translate_transformer_temp.csv\", index=False)\n","\n","    data_fields = [('src', SRC), ('trg', TRG)]\n","    train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n","\n","    train_iter = MyIterator(train, batch_size=batchsize, device=device,\n","                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n","                        batch_size_fn=batch_size_fn, train=istrain, shuffle=True)\n","\n","    os.remove('translate_transformer_temp.csv')\n","\n","    if istrain:\n","        SRC.build_vocab(train)\n","        TRG.build_vocab(train)\n","\n","    return train_iter"]},{"cell_type":"markdown","metadata":{},"source":["# Config"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T19:06:00.929706Z","iopub.status.busy":"2024-12-13T19:06:00.929051Z","iopub.status.idle":"2024-12-13T19:06:00.934326Z","shell.execute_reply":"2024-12-13T19:06:00.933431Z","shell.execute_reply.started":"2024-12-13T19:06:00.929671Z"},"id":"WMnc1JaTlRLt","trusted":true},"outputs":[],"source":["opt = {\n","    'max_strlen':128,\n","    'batchsize':1500,\n","    'device':torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n","    'd_model': 512,\n","    'n_layers': 6,\n","    'heads': 8,\n","    'dropout': 0.1,\n","    'lr':0.0001,\n","    'epochs': 25,\n","    'printevery': 200,\n","    'k':5,\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-12-13T18:00:07.692733Z","iopub.status.busy":"2024-12-13T18:00:07.692027Z","iopub.status.idle":"2024-12-13T18:01:05.645825Z","shell.execute_reply":"2024-12-13T18:01:05.644827Z","shell.execute_reply.started":"2024-12-13T18:00:07.692694Z"},"id":"9bMnDrd4gwgp","outputId":"feb2f0ba-a5ea-48d9-ce1b-2715cb860fa2","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["loading spacy tokenizers...\n","creating dataset and iterator... \n","creating dataset and iterator... \n"]}],"source":["train_src_data, train_trg_data = train_data['English'], train_data['Vietnamese']\n","valid_src_data, valid_trg_data = valid_data['English'], valid_data['Vietnamese']\n","SRC, TRG = create_fields('en_core_web_sm', 'vi_core_news_lg')\n","train_iter = create_dataset(train_src_data, train_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=True)\n","valid_iter = create_dataset(valid_src_data, valid_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=False)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T18:02:02.267688Z","iopub.status.busy":"2024-12-13T18:02:02.267062Z","iopub.status.idle":"2024-12-13T18:02:02.271735Z","shell.execute_reply":"2024-12-13T18:02:02.270861Z","shell.execute_reply.started":"2024-12-13T18:02:02.267649Z"},"id":"RLzktLMZgxxo","trusted":true},"outputs":[],"source":["src_pad = SRC.vocab.stoi['<pad>']\n","trg_pad = TRG.vocab.stoi['<pad>']"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T19:06:11.727782Z","iopub.status.busy":"2024-12-13T19:06:11.726945Z","iopub.status.idle":"2024-12-13T19:06:13.973855Z","shell.execute_reply":"2024-12-13T19:06:13.973134Z","shell.execute_reply.started":"2024-12-13T19:06:11.727743Z"},"id":"vFkvSZtNgy3w","trusted":true},"outputs":[],"source":["model = Transformer(len(SRC.vocab), len(TRG.vocab), opt['d_model'], opt['n_layers'], opt['heads'], opt['dropout'])\n","\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","model = model.to(opt['device'])"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T20:14:46.093584Z","iopub.status.busy":"2024-12-13T20:14:46.093195Z","iopub.status.idle":"2024-12-13T20:14:46.099913Z","shell.execute_reply":"2024-12-13T20:14:46.099012Z","shell.execute_reply.started":"2024-12-13T20:14:46.093550Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 66,239,419 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    \n","print(f\"The model has {count_parameters(model):,} trainable parameters\")"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T19:06:17.761041Z","iopub.status.busy":"2024-12-13T19:06:17.760735Z","iopub.status.idle":"2024-12-13T19:06:17.766934Z","shell.execute_reply":"2024-12-13T19:06:17.765822Z","shell.execute_reply.started":"2024-12-13T19:06:17.761013Z"},"id":"WfPxI9bHg9BB","trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(model.parameters(), lr=opt['lr'], betas=(0.9, 0.98), eps=1e-9)"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T19:06:24.782552Z","iopub.status.busy":"2024-12-13T19:06:24.781736Z","iopub.status.idle":"2024-12-13T19:06:24.790665Z","shell.execute_reply":"2024-12-13T19:06:24.789717Z","shell.execute_reply.started":"2024-12-13T19:06:24.782516Z"},"trusted":true},"outputs":[],"source":["def step(model, optimizer,batch, criterion):\n","    model.train()\n","\n","    src = batch.src.transpose(0,1).to(opt['device'])\n","    trg = batch.trg.transpose(0,1).to(opt['device'])\n","    trg_input = trg[:, :-1]\n","    src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n","    preds = model(src, trg_input, src_mask, trg_mask)\n","\n","    ys = trg[:, 1:].contiguous().view(-1)\n","\n","    optimizer.zero_grad()\n","    loss = criterion(preds.view(-1, preds.size(-1)), ys)\n","    loss.backward()\n","    optimizer.step()\n","\n","    loss = loss.item()\n","\n","    return loss\n","\n","\n","def validiate(model, valid_iter, criterion):\n","    model.eval()\n","\n","    with torch.no_grad():\n","        total_loss = []\n","        for batch in valid_iter:\n","            src = batch.src.transpose(0,1).to(opt['device'])\n","            trg = batch.trg.transpose(0,1).to(opt['device'])\n","            trg_input = trg[:, :-1]\n","            src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n","            preds = model(src, trg_input, src_mask, trg_mask)\n","\n","            ys = trg[:, 1:].contiguous().view(-1)\n","\n","            loss = criterion(preds.view(-1, preds.size(-1)), ys)\n","\n","            loss = loss.item()\n","\n","            total_loss.append(loss)\n","\n","    avg_loss = np.mean(total_loss)\n","\n","    return avg_loss"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T19:06:27.658677Z","iopub.status.busy":"2024-12-13T19:06:27.657887Z","iopub.status.idle":"2024-12-13T19:06:27.663618Z","shell.execute_reply":"2024-12-13T19:06:27.662713Z","shell.execute_reply.started":"2024-12-13T19:06:27.658641Z"},"trusted":true},"outputs":[],"source":["def save_model(model, path=\"bestmodel.pt\"):\n","    \"\"\"\n","    Save the model state\n","    Args:\n","        model: The model\n","        path: The save path\n","    \"\"\"\n","    torch.save(model.state_dict(), path)\n","    print(f\"Model saved to {path}!\")\n","\n","\n","def load_model(model, path=\"bestmodel.pt\"):\n","    \"\"\"\n","    Load model from a saved state\n","    Args:\n","        model: The model\n","        path: The save path\n","    Returns:\n","        model: The updated model\n","    \"\"\"\n","    model.load_state_dict(torch.load(path))\n","    model.eval()  # Eval mode\n","    print(f\"Model loaded from {path}!\")\n","    return model"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451,"referenced_widgets":["af6bdc65ea44416ba28885faf60a0f52","de6a111350b44c6b831ba32240b311eb","432b4e6ee9f04d42a8a643c21106f60b","431326e9b841495f97e88c3ae1e284a4","7d2ce60a1d544a72b713dc95363ad1f9","9a18e8f29cac485b934041350cd5fb96","3b8eb9060dda4d86b3d9b4e571f91aed","706e5dcc9eec4b629585bad0bd901f5a","3444266d74f945cdb3809cd29a765ca1","6426742fd55941edb51ab2ca282b1a56","34b53deb7eba4294b8186f8cd9443224"]},"execution":{"iopub.execute_input":"2024-12-13T19:06:40.220742Z","iopub.status.busy":"2024-12-13T19:06:40.220410Z","iopub.status.idle":"2024-12-13T20:09:15.463465Z","shell.execute_reply":"2024-12-13T20:09:15.462537Z","shell.execute_reply.started":"2024-12-13T19:06:40.220712Z"},"id":"quBB6Byzg-pp","outputId":"e6f73d98-858f-4ed7-fbf3-274281298883","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_23/2231454454.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for i, batch in tqdm(enumerate(train_iter)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3768b4074f964e66aa3e0e340e2aae6e","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 000 - iter: 00000 - train loss: 0.0471\n","epoch: 000 - iter: 00200 - train loss: 5.7409\n","epoch: 000 - iter: 00400 - train loss: 4.4586\n","epoch: 000 - iter: 00600 - train loss: 3.8893\n","epoch: 000 - iter: 00800 - train loss: 3.4578\n","epoch: 000 - iter: 01000 - train loss: 3.0734\n","epoch: 000 - iter: 01200 - train loss: 2.7049\n","Model saved to bestmodel.pt!\n","epoch: 000 - iter: 01345 - train loss: 3.7373 - valid loss: 2.1523 - time: 5.9288\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8ebf5ec61f24930a70e82ef5ec9c597","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 001 - iter: 00000 - train loss: 0.0120\n","epoch: 001 - iter: 00200 - train loss: 2.2935\n","epoch: 001 - iter: 00400 - train loss: 2.0572\n","epoch: 001 - iter: 00600 - train loss: 1.8968\n","epoch: 001 - iter: 00800 - train loss: 1.7668\n","epoch: 001 - iter: 01000 - train loss: 1.6839\n","epoch: 001 - iter: 01200 - train loss: 1.5576\n","epoch: 001 - iter: 01344 - train loss: 1.8321 - valid loss: 1.2998 - time: 5.5832\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04bf92700ad64fcc8259ad5be7593911","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 002 - iter: 00000 - train loss: 0.0069\n","epoch: 002 - iter: 00200 - train loss: 1.3656\n","epoch: 002 - iter: 00400 - train loss: 1.3535\n","epoch: 002 - iter: 00600 - train loss: 1.2821\n","epoch: 002 - iter: 00800 - train loss: 1.2371\n","epoch: 002 - iter: 01000 - train loss: 1.2177\n","epoch: 002 - iter: 01200 - train loss: 1.1251\n","epoch: 002 - iter: 01344 - train loss: 1.2492 - valid loss: 1.0010 - time: 5.5735\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"370a382c7edf48bf93df7581ebe54a91","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 003 - iter: 00000 - train loss: 0.0047\n","epoch: 003 - iter: 00200 - train loss: 1.0289\n","epoch: 003 - iter: 00400 - train loss: 1.0280\n","epoch: 003 - iter: 00600 - train loss: 0.9763\n","epoch: 003 - iter: 00800 - train loss: 0.9872\n","epoch: 003 - iter: 01000 - train loss: 0.9875\n","epoch: 003 - iter: 01200 - train loss: 0.9269\n","epoch: 003 - iter: 01345 - train loss: 0.9812 - valid loss: 0.8348 - time: 5.5779\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eecec1936e7b43bd80258174934a9ed2","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 004 - iter: 00000 - train loss: 0.0036\n","epoch: 004 - iter: 00200 - train loss: 0.8414\n","epoch: 004 - iter: 00400 - train loss: 0.8367\n","epoch: 004 - iter: 00600 - train loss: 0.8303\n","epoch: 004 - iter: 00800 - train loss: 0.8365\n","epoch: 004 - iter: 01000 - train loss: 0.8052\n","epoch: 004 - iter: 01200 - train loss: 0.7968\n","epoch: 004 - iter: 01344 - train loss: 0.8194 - valid loss: 0.7518 - time: 5.5738\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9e9c31aeced4a63ac809396c7857994","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 005 - iter: 00000 - train loss: 0.0038\n","epoch: 005 - iter: 00200 - train loss: 0.7300\n","epoch: 005 - iter: 00400 - train loss: 0.6950\n","epoch: 005 - iter: 00600 - train loss: 0.7205\n","epoch: 005 - iter: 00800 - train loss: 0.7298\n","epoch: 005 - iter: 01000 - train loss: 0.7010\n","epoch: 005 - iter: 01200 - train loss: 0.6910\n","epoch: 005 - iter: 01343 - train loss: 0.7101 - valid loss: 0.6999 - time: 5.5810\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6bb553b995242e78d37650c27ef7db9","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 006 - iter: 00000 - train loss: 0.0030\n","epoch: 006 - iter: 00200 - train loss: 0.6409\n","epoch: 006 - iter: 00400 - train loss: 0.6364\n","epoch: 006 - iter: 00600 - train loss: 0.6321\n","epoch: 006 - iter: 00800 - train loss: 0.6278\n","epoch: 006 - iter: 01000 - train loss: 0.6215\n","epoch: 006 - iter: 01200 - train loss: 0.6261\n","epoch: 006 - iter: 01344 - train loss: 0.6294 - valid loss: 0.6631 - time: 5.5767\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5116fa1eb1f344c7996098624dd0f518","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 007 - iter: 00000 - train loss: 0.0030\n","epoch: 007 - iter: 00200 - train loss: 0.5523\n","epoch: 007 - iter: 00400 - train loss: 0.5674\n","epoch: 007 - iter: 00600 - train loss: 0.5676\n","epoch: 007 - iter: 00800 - train loss: 0.5807\n","epoch: 007 - iter: 01000 - train loss: 0.5703\n","epoch: 007 - iter: 01200 - train loss: 0.5581\n","epoch: 007 - iter: 01344 - train loss: 0.5651 - valid loss: 0.6310 - time: 5.5341\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77353cd16caa44e0809269a8037426f6","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 008 - iter: 00000 - train loss: 0.0024\n","epoch: 008 - iter: 00200 - train loss: 0.4961\n","epoch: 008 - iter: 00400 - train loss: 0.5082\n","epoch: 008 - iter: 00600 - train loss: 0.5212\n","epoch: 008 - iter: 00800 - train loss: 0.5179\n","epoch: 008 - iter: 01000 - train loss: 0.5266\n","epoch: 008 - iter: 01200 - train loss: 0.5309\n","epoch: 008 - iter: 01344 - train loss: 0.5156 - valid loss: 0.6173 - time: 5.5901\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e025906149d848e6b8b948289096d0fe","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 009 - iter: 00000 - train loss: 0.0040\n","epoch: 009 - iter: 00200 - train loss: 0.4555\n","epoch: 009 - iter: 00400 - train loss: 0.4616\n","epoch: 009 - iter: 00600 - train loss: 0.4685\n","epoch: 009 - iter: 00800 - train loss: 0.4799\n","epoch: 009 - iter: 01000 - train loss: 0.4863\n","epoch: 009 - iter: 01200 - train loss: 0.4687\n","epoch: 009 - iter: 01344 - train loss: 0.4734 - valid loss: 0.5980 - time: 5.5823\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"032abb1ba8034e55a6e9d001630ce426","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 010 - iter: 00000 - train loss: 0.0015\n","epoch: 010 - iter: 00200 - train loss: 0.4224\n","epoch: 010 - iter: 00400 - train loss: 0.4206\n","epoch: 010 - iter: 00600 - train loss: 0.4274\n","epoch: 010 - iter: 00800 - train loss: 0.4487\n","epoch: 010 - iter: 01000 - train loss: 0.4536\n","epoch: 010 - iter: 01200 - train loss: 0.4317\n","epoch: 010 - iter: 01345 - train loss: 0.4365 - valid loss: 0.5901 - time: 5.5563\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae69018c9a7143168f67ee62c1fd3d33","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 011 - iter: 00000 - train loss: 0.0018\n","epoch: 011 - iter: 00200 - train loss: 0.3835\n","epoch: 011 - iter: 00400 - train loss: 0.3982\n","epoch: 011 - iter: 00600 - train loss: 0.4084\n","epoch: 011 - iter: 00800 - train loss: 0.4121\n","epoch: 011 - iter: 01000 - train loss: 0.4226\n","epoch: 011 - iter: 01200 - train loss: 0.4048\n","epoch: 011 - iter: 01344 - train loss: 0.4053 - valid loss: 0.5750 - time: 5.5850\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc807fb2d7f74c318e02b1ab84e1fde5","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 012 - iter: 00000 - train loss: 0.0018\n","epoch: 012 - iter: 00200 - train loss: 0.3603\n","epoch: 012 - iter: 00400 - train loss: 0.3751\n","epoch: 012 - iter: 00600 - train loss: 0.3900\n","epoch: 012 - iter: 00800 - train loss: 0.3808\n","epoch: 012 - iter: 01000 - train loss: 0.3856\n","epoch: 012 - iter: 01200 - train loss: 0.3874\n","Model saved to bestmodel.pt!\n","epoch: 012 - iter: 01345 - train loss: 0.3795 - valid loss: 0.5772 - time: 6.2017\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb2bac88a8694967bc40aabb6a18b5de","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 013 - iter: 00000 - train loss: 0.0016\n","epoch: 013 - iter: 00200 - train loss: 0.3375\n","epoch: 013 - iter: 00400 - train loss: 0.3475\n","epoch: 013 - iter: 00600 - train loss: 0.3568\n","epoch: 013 - iter: 00800 - train loss: 0.3654\n","epoch: 013 - iter: 01000 - train loss: 0.3688\n","epoch: 013 - iter: 01200 - train loss: 0.3649\n","epoch: 013 - iter: 01344 - train loss: 0.3563 - valid loss: 0.5751 - time: 5.5732\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10daf7ff38434f92a051230be4bbce5e","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 014 - iter: 00000 - train loss: 0.0013\n","epoch: 014 - iter: 00200 - train loss: 0.3228\n","epoch: 014 - iter: 00400 - train loss: 0.3270\n","epoch: 014 - iter: 00600 - train loss: 0.3235\n","epoch: 014 - iter: 00800 - train loss: 0.3437\n","epoch: 014 - iter: 01000 - train loss: 0.3409\n","epoch: 014 - iter: 01200 - train loss: 0.3364\n","epoch: 014 - iter: 01344 - train loss: 0.3334 - valid loss: 0.5715 - time: 5.5818\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed4baa2c7df747d997a999895400870e","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 015 - iter: 00000 - train loss: 0.0015\n","epoch: 015 - iter: 00200 - train loss: 0.2977\n","epoch: 015 - iter: 00400 - train loss: 0.3080\n","epoch: 015 - iter: 00600 - train loss: 0.2983\n","epoch: 015 - iter: 00800 - train loss: 0.3178\n","epoch: 015 - iter: 01000 - train loss: 0.3201\n","epoch: 015 - iter: 01200 - train loss: 0.3178\n","Model saved to bestmodel.pt!\n","epoch: 015 - iter: 01345 - train loss: 0.3121 - valid loss: 0.5638 - time: 6.1837\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5296ebf0286b4b419685a668037b4762","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 016 - iter: 00000 - train loss: 0.0014\n","epoch: 016 - iter: 00200 - train loss: 0.2845\n","epoch: 016 - iter: 00400 - train loss: 0.2849\n","epoch: 016 - iter: 00600 - train loss: 0.2928\n","epoch: 016 - iter: 00800 - train loss: 0.2955\n","epoch: 016 - iter: 01000 - train loss: 0.3018\n","epoch: 016 - iter: 01200 - train loss: 0.3033\n","Model saved to bestmodel.pt!\n","epoch: 016 - iter: 01344 - train loss: 0.2953 - valid loss: 0.5623 - time: 6.2317\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed3a9368e4af4bf08d46500da592fda4","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 017 - iter: 00000 - train loss: 0.0013\n","epoch: 017 - iter: 00200 - train loss: 0.2557\n","epoch: 017 - iter: 00400 - train loss: 0.2700\n","epoch: 017 - iter: 00600 - train loss: 0.2854\n","epoch: 017 - iter: 00800 - train loss: 0.2817\n","epoch: 017 - iter: 01000 - train loss: 0.2882\n","epoch: 017 - iter: 01200 - train loss: 0.2789\n","Model saved to bestmodel.pt!\n","epoch: 017 - iter: 01344 - train loss: 0.2787 - valid loss: 0.5643 - time: 6.1845\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be9ae954fa7d4ba0a5ed05d22949bab7","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 018 - iter: 00000 - train loss: 0.0011\n","epoch: 018 - iter: 00200 - train loss: 0.2527\n","epoch: 018 - iter: 00400 - train loss: 0.2586\n","epoch: 018 - iter: 00600 - train loss: 0.2633\n","epoch: 018 - iter: 00800 - train loss: 0.2634\n","epoch: 018 - iter: 01000 - train loss: 0.2639\n","epoch: 018 - iter: 01200 - train loss: 0.2718\n","epoch: 018 - iter: 01346 - train loss: 0.2639 - valid loss: 0.5645 - time: 5.5152\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f3c275d4a9e478f88407b331f0ef8e1","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 019 - iter: 00000 - train loss: 0.0009\n","epoch: 019 - iter: 00200 - train loss: 0.2308\n","epoch: 019 - iter: 00400 - train loss: 0.2410\n","epoch: 019 - iter: 00600 - train loss: 0.2514\n","epoch: 019 - iter: 00800 - train loss: 0.2524\n","epoch: 019 - iter: 01000 - train loss: 0.2603\n","epoch: 019 - iter: 01200 - train loss: 0.2595\n","epoch: 019 - iter: 01344 - train loss: 0.2502 - valid loss: 0.5713 - time: 5.5739\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3d7d26e0c26491c8b2e35490ba4e25e","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 020 - iter: 00000 - train loss: 0.0011\n","epoch: 020 - iter: 00200 - train loss: 0.2250\n","epoch: 020 - iter: 00400 - train loss: 0.2251\n","epoch: 020 - iter: 00600 - train loss: 0.2317\n","epoch: 020 - iter: 00800 - train loss: 0.2497\n","epoch: 020 - iter: 01000 - train loss: 0.2413\n","epoch: 020 - iter: 01200 - train loss: 0.2401\n","epoch: 020 - iter: 01345 - train loss: 0.2373 - valid loss: 0.5702 - time: 5.5868\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99618f5b36584a278f734765e0fd8a27","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 021 - iter: 00000 - train loss: 0.0014\n","epoch: 021 - iter: 00200 - train loss: 0.2111\n","epoch: 021 - iter: 00400 - train loss: 0.2137\n","epoch: 021 - iter: 00600 - train loss: 0.2202\n","epoch: 021 - iter: 00800 - train loss: 0.2312\n","epoch: 021 - iter: 01000 - train loss: 0.2362\n","epoch: 021 - iter: 01200 - train loss: 0.2320\n","epoch: 021 - iter: 01343 - train loss: 0.2254 - valid loss: 0.5812 - time: 5.5669\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bddbc01238d46c58d577ae2a0c619d1","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 022 - iter: 00000 - train loss: 0.0010\n","epoch: 022 - iter: 00200 - train loss: 0.2017\n","epoch: 022 - iter: 00400 - train loss: 0.2045\n","epoch: 022 - iter: 00600 - train loss: 0.2159\n","epoch: 022 - iter: 00800 - train loss: 0.2206\n","epoch: 022 - iter: 01000 - train loss: 0.2161\n","epoch: 022 - iter: 01200 - train loss: 0.2210\n","epoch: 022 - iter: 01343 - train loss: 0.2149 - valid loss: 0.5764 - time: 5.5742\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9477fe96e0764369abb1464ab3eefed0","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 023 - iter: 00000 - train loss: 0.0012\n","epoch: 023 - iter: 00200 - train loss: 0.1914\n","epoch: 023 - iter: 00400 - train loss: 0.1960\n","epoch: 023 - iter: 00600 - train loss: 0.2016\n","epoch: 023 - iter: 00800 - train loss: 0.2075\n","epoch: 023 - iter: 01000 - train loss: 0.2125\n","epoch: 023 - iter: 01200 - train loss: 0.2115\n","epoch: 023 - iter: 01346 - train loss: 0.2050 - valid loss: 0.5780 - time: 5.5629\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f847c75f359c4015ad5e6d8a30bf66dc","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 024 - iter: 00000 - train loss: 0.0008\n","epoch: 024 - iter: 00200 - train loss: 0.1784\n","epoch: 024 - iter: 00400 - train loss: 0.1838\n","epoch: 024 - iter: 00600 - train loss: 0.1988\n","epoch: 024 - iter: 00800 - train loss: 0.2055\n","epoch: 024 - iter: 01000 - train loss: 0.2023\n","epoch: 024 - iter: 01200 - train loss: 0.1996\n","epoch: 024 - iter: 01345 - train loss: 0.1961 - valid loss: 0.5891 - time: 5.5753\n"]}],"source":["train_losses = []\n","valid_losses = []\n","best_valid_loss = float('inf')\n","for epoch in range(opt['epochs']):\n","    total_loss = 0\n","    epoch_train_loss = 0\n","    epoch_size = 0\n","    s = time.time()\n","    for i, batch in tqdm(enumerate(train_iter)):\n","        s = time.time()\n","        loss = step(model, optimizer, batch, criterion)\n","        \n","        total_loss += loss\n","        epoch_train_loss += loss \n","        epoch_size += 1\n","        \n","        if (i + 1) % 200 == 1:\n","            avg_loss = total_loss/200\n","            print('epoch: {:03d} - iter: {:05d} - train loss: {:.4f}'.format(epoch, i, avg_loss))\n","            total_loss = 0\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        save_model(model)\n","    \n","    epoch_avg_loss = epoch_train_loss / epoch_size\n","    valid_loss = validiate(model, valid_iter, criterion)\n","    train_losses.append(epoch_avg_loss)\n","    valid_losses.append(valid_loss)\n","    print('epoch: {:03d} - iter: {:05d} - train loss: {:.4f} - valid loss: {:.4f} - time: {:.4f}'.format(epoch, i, epoch_avg_loss,  valid_loss, time.time() - s))\n"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T20:14:11.921530Z","iopub.status.busy":"2024-12-13T20:14:11.921160Z","iopub.status.idle":"2024-12-13T20:14:12.120656Z","shell.execute_reply":"2024-12-13T20:14:12.119800Z","shell.execute_reply.started":"2024-12-13T20:14:11.921500Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","def plot_loss(train_losses, val_losses):\n","    epochs = range(1, len(train_losses) + 1)\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(epochs, train_losses, marker='o', label='Train Loss')\n","    plt.plot(epochs, val_losses, marker='o', label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title('Training and Validation Loss')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","plot_loss(train_losses, valid_losses)"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T20:21:16.238309Z","iopub.status.busy":"2024-12-13T20:21:16.237927Z","iopub.status.idle":"2024-12-13T20:21:18.267673Z","shell.execute_reply":"2024-12-13T20:21:18.266791Z","shell.execute_reply.started":"2024-12-13T20:21:16.238275Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_23/1585372437.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(path))\n"]},{"name":"stdout","output_type":"stream","text":["Model loaded from bestmodel.pt!\n"]},{"data":{"text/plain":["Transformer(\n","  (encoder): Encoder(\n","    (embed): Embedder(\n","      (embed): Embedding(18700, 512)\n","    )\n","    (pe): PositionalEncoder(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layers): ModuleList(\n","      (0-5): 6 x EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): Decoder(\n","    (embed): Embedder(\n","      (embed): Embedding(12219, 512)\n","    )\n","    (pe): PositionalEncoder(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layers): ModuleList(\n","      (0-5): 6 x DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=12219, bias=True)\n",")"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["eval_model = Transformer(len(SRC.vocab), len(TRG.vocab), opt['d_model'], opt['n_layers'], opt['heads'], opt['dropout'])\n","\n","load_model(eval_model)\n","eval_model.to(opt['device'])"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T20:21:34.532587Z","iopub.status.busy":"2024-12-13T20:21:34.532197Z","iopub.status.idle":"2024-12-13T20:21:34.760710Z","shell.execute_reply":"2024-12-13T20:21:34.759845Z","shell.execute_reply.started":"2024-12-13T20:21:34.532554Z"},"id":"0db-AEmmlxEF","trusted":true},"outputs":[{"data":{"text/plain":["'gia_đình tôi không nghèo, và tôi chưa bao_giờ trải qua cơn đói.'"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["sentence='My family was not poor , and myself , I had never experienced hunger .'\n","trans_sent = translate_sentence(sentence, eval_model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n","trans_sent"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T20:24:04.092480Z","iopub.status.busy":"2024-12-13T20:24:04.091806Z","iopub.status.idle":"2024-12-13T20:24:04.215660Z","shell.execute_reply":"2024-12-13T20:24:04.214838Z","shell.execute_reply.started":"2024-12-13T20:24:04.092443Z"},"id":"1Obu7Nw6hBAy","trusted":true},"outputs":[{"data":{"text/plain":["'đôi_khi, tôi không cảm_thấy tốt'"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["sentence='Sometime, I do not feel so good'\n","trans_sent = translate_sentence(sentence, eval_model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n","trans_sent"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T20:24:09.762985Z","iopub.status.busy":"2024-12-13T20:24:09.762674Z","iopub.status.idle":"2024-12-13T20:24:10.535864Z","shell.execute_reply":"2024-12-13T20:24:10.534965Z","shell.execute_reply.started":"2024-12-13T20:24:09.762958Z"},"id":"vc5dah8c1UlU","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tôi thích dành thời_gian ngoài_trời, đặc_biệt là thời_tiết đẹp.\n","tiếng mưa của mưa đâm mái nhà rất đối_với tôi.\n","bất_cứ khi nào tôi cảm_thấy căng_thẳng, tôi muốn đi dạo trong công_viên.\n","mùi bánh_quy tươi luôn làm tôi nhớ về thời thơ_ấu của mình.\n"]}],"source":["sentences = ['I enjoy spending time outdoors, especially when the weather is nice.',\n","            'The sound of rain hitting the roof is very soothing to me.',\n","            'Whenever I feel stressed, I like to take a long walk in the park.',\n","            'The smell of fresh-baked cookies always reminds me of my childhood.']\n","\n","for sentence in sentences:\n","    trans_sent = translate_sentence(sentence, eval_model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n","    print(trans_sent)"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T20:24:15.658302Z","iopub.status.busy":"2024-12-13T20:24:15.657700Z","iopub.status.idle":"2024-12-13T20:24:15.776408Z","shell.execute_reply":"2024-12-13T20:24:15.775554Z","shell.execute_reply.started":"2024-12-13T20:24:15.658238Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cô bán vỏ dự_phòng trên bờ biển\n"]}],"source":["sentences = ['she sells seashell on the seashore']\n","\n","for sentence in sentences:\n","    trans_sent = translate_sentence(sentence, eval_model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n","    print(trans_sent)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T17:57:01.130223Z","iopub.status.busy":"2024-12-13T17:57:01.129413Z","iopub.status.idle":"2024-12-13T17:57:01.135619Z","shell.execute_reply":"2024-12-13T17:57:01.134553Z","shell.execute_reply.started":"2024-12-13T17:57:01.130189Z"},"id":"1k_ozjsmlfy9","trusted":true},"outputs":[],"source":["def bleu(valid_src_data, valid_trg_data, model, SRC, TRG, device, k, max_strlen):\n","    pred_sents = []\n","    for sentence in tqdm(valid_src_data):\n","        pred_trg = translate_sentence(sentence, model, SRC, TRG, device, k, max_strlen)\n","        pred_sents.append(pred_trg)\n","\n","    pred_sents = [TRG.preprocess(sent) for sent in pred_sents]\n","    trg_sents = [[sent.split()] for sent in valid_trg_data]\n","\n","    return bleu_score(pred_sents, trg_sents)"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-12-13T20:27:35.312183Z","iopub.status.busy":"2024-12-13T20:27:35.311386Z","iopub.status.idle":"2024-12-13T21:24:25.744429Z","shell.execute_reply":"2024-12-13T21:24:25.743579Z","shell.execute_reply.started":"2024-12-13T20:27:35.312146Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_23/1025466030.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for sentence in tqdm(valid_src_data):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92a8b7d0df7e41aca6455c0f2104bfea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/25409 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["0.3403435176258633"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["bleu(valid_src_data, valid_trg_data, eval_model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3444266d74f945cdb3809cd29a765ca1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34b53deb7eba4294b8186f8cd9443224":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b8eb9060dda4d86b3d9b4e571f91aed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"431326e9b841495f97e88c3ae1e284a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6426742fd55941edb51ab2ca282b1a56","placeholder":"​","style":"IPY_MODEL_34b53deb7eba4294b8186f8cd9443224","value":" 341/? [00:58&lt;00:00,  5.83it/s]"}},"432b4e6ee9f04d42a8a643c21106f60b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_706e5dcc9eec4b629585bad0bd901f5a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3444266d74f945cdb3809cd29a765ca1","value":1}},"6426742fd55941edb51ab2ca282b1a56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"706e5dcc9eec4b629585bad0bd901f5a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7d2ce60a1d544a72b713dc95363ad1f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a18e8f29cac485b934041350cd5fb96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af6bdc65ea44416ba28885faf60a0f52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de6a111350b44c6b831ba32240b311eb","IPY_MODEL_432b4e6ee9f04d42a8a643c21106f60b","IPY_MODEL_431326e9b841495f97e88c3ae1e284a4"],"layout":"IPY_MODEL_7d2ce60a1d544a72b713dc95363ad1f9"}},"de6a111350b44c6b831ba32240b311eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a18e8f29cac485b934041350cd5fb96","placeholder":"​","style":"IPY_MODEL_3b8eb9060dda4d86b3d9b4e571f91aed","value":""}}}}},"nbformat":4,"nbformat_minor":4}
